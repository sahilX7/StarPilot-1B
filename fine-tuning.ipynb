{"cells":[{"cell_type":"markdown","id":"d4d95ab6","metadata":{"id":"d4d95ab6"},"source":["## **Fine-Tuning Pipeline for StarCoder (Copilot-Style)**\n","\n","This notebook implements a pipeline to fine-tune `starcoderbase-1b` to create **\"StarPilot-1B\"**, a GitHub Copilot-style coding assistant specialized in Python."]},{"cell_type":"markdown","id":"e47bf0ec","metadata":{"id":"e47bf0ec"},"source":["##### Environment Setup & Imports\n","We mount google drive, install the necessary libraries for efficient LLM training (`bitsandbytes` for quantization, `peft` for LoRA, `trl` for the training loop) and import core modules."]},{"cell_type":"code","execution_count":1,"id":"85VOlqoDr-p2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":96927,"status":"ok","timestamp":1768904576514,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"85VOlqoDr-p2","outputId":"4d500a9f-018f-4006-9f0b-794a031e1915"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Sahil/Fine-Tuning\n"]}],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change Path\n","%cd /content/drive/MyDrive/Sahil/Fine-Tuning"]},{"cell_type":"code","execution_count":2,"id":"30fc23f8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7411,"status":"ok","timestamp":1768904583923,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"30fc23f8","outputId":"9d5bf452-862c-4492-f1ae-150d401bb576"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/532.5 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install required libraries\n","!pip install -q transformers datasets peft bitsandbytes trl accelerate"]},{"cell_type":"code","execution_count":3,"id":"fc3eef22","metadata":{"executionInfo":{"elapsed":25033,"status":"ok","timestamp":1768904609055,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"fc3eef22"},"outputs":[],"source":["# Import modules\n","import torch\n","import re\n","import os\n","import numpy as np\n","import warnings\n","from dataclasses import dataclass\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    DataCollatorForLanguageModeling,\n","    EarlyStoppingCallback,\n","    TrainerCallback,\n","    TrainerState,\n","    TrainerControl\n",")\n","from transformers.trainer_callback import PrinterCallback\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","from trl import SFTTrainer, SFTConfig\n","\n","# Ignore warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":6,"id":"0b051a2d","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1768904639891,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"0b051a2d"},"outputs":[],"source":["# Hugging Face Login\n","from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"markdown","id":"a6c075a7","metadata":{"id":"a6c075a7"},"source":["##### Configuration Management\n","Here we define the necessary configurations."]},{"cell_type":"code","execution_count":7,"id":"363a21f4","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1768904649125,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"363a21f4"},"outputs":[],"source":["@dataclass\n","class ModelConfig:\n","    model_id: str = \"bigcode/starcoderbase-1b\"\n","    dataset_id: str = \"ise-uiuc/Magicoder-Evol-Instruct-110K\"\n","    tuned_model_id: str = \"starpilot-1b-v1\"\n","    load_in_4bit: bool = True\n","    bnb_compute_dtype: str = \"bfloat16\"\n","\n","@dataclass\n","class LoRAConfig:\n","    r: int = 32\n","    alpha: int = 64\n","    dropout: float = 0.05\n","    target_modules: str = \"all-linear\"\n","\n","@dataclass\n","class TrainConfig:\n","    # Precision & Hardware\n","    bf16: bool = True\n","    fp16: bool = False\n","    gradient_checkpointing: bool = True\n","\n","    # Data Processing\n","    dataset_text_field: str = \"code\"\n","    max_length: int = 2048\n","    packing: bool = False\n","    group_by_length: bool = True\n","\n","    # Training Loop & Optimization\n","    max_steps: int = 4000\n","    batch_size: int = 8\n","    grad_accum: int = 4\n","    patience: int = 3\n","    optim: str = \"paged_adamw_32bit\"\n","    lr_scheduler_type: str = \"cosine\"\n","    learning_rate: float = 2e-4\n","    warmup_steps: int = 100\n","    weight_decay: float = 0.01\n","\n","    # Evaluation\n","    eval_strategy: str = \"steps\"\n","    eval_steps: int = 200\n","    eval_batch_size: int = 32\n","\n","    # Logging\n","    disable_tqdm: bool = True\n","    logging_strategy: str = \"steps\"\n","    logging_steps: int = 200\n","    report_to: str = \"none\"\n","\n","\n","    # Checkpoints & Saving\n","    output_dir: str = \"./checkpoints\"\n","    save_strategy: str = \"steps\"\n","    save_steps: int = 200\n","    save_total_limit: int = 5\n","    load_best_model_at_end: bool = True\n","    metric_for_best_model: str = \"eval_loss\"\n","    greater_is_better: bool = False"]},{"cell_type":"markdown","id":"7cc5ec89","metadata":{"id":"7cc5ec89"},"source":["##### Data Pipeline\n","We parse the Magicoder dataset to extract python code and reformat it into a Comment -> Code structure. This teaches the model to treat comments as prompts, mimicking the GitHub Copilot autocomplete feature."]},{"cell_type":"code","execution_count":8,"id":"8a208440","metadata":{"id":"8a208440","executionInfo":{"status":"ok","timestamp":1768904662628,"user_tz":-330,"elapsed":2,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["class DataPipeline:\n","    def __init__(self, config: ModelConfig, tokenizer: AutoTokenizer):\n","        self.config = config\n","        self.tokenizer = tokenizer\n","        self.separator = \"\\n# Solution:\\n\"\n","\n","    def format_instruction(self, example):\n","        \"\"\"\n","        Formats as a python comment followed by code to mimic Copilot autocomplete behavior.\n","        \"\"\"\n","        instruction = example.get('instruction', '')\n","        response = example.get('response', '')\n","\n","        # Extract code block wrapped in markdown\n","        code_blocks = re.findall(r'```python\\s*(.*?)\\s*```', response, re.DOTALL)\n","        if not code_blocks:\n","            return {\"code\": None}\n","\n","        code_content = \"\\n\\n\".join(code_blocks)\n","\n","        # Construct training prompt\n","        formatted_text = f'# {instruction}{self.separator}{code_content}{self.tokenizer.eos_token}'\n","\n","        return {\"code\": formatted_text}\n","\n","    def load_and_prepare(self):\n","        print(f\"Loading dataset: {self.config.dataset_id}\")\n","        dataset = load_dataset(self.config.dataset_id, split=\"train\")\n","\n","        print(\"Formatting dataset for Copilot style...\")\n","        dataset = dataset.map(self.format_instruction)\n","\n","        # Filter data\n","        dataset = dataset.filter(lambda x: x['code'] is not None and len(x['code'].strip()) > 0)\n","\n","        # Train-Validation Split\n","        split_dataset = dataset.train_test_split(test_size=0.08)\n","        print(f\"Train size: {len(split_dataset['train'])}, Validation size: {len(split_dataset['test'])}\")\n","\n","        return split_dataset['train'], split_dataset['test']"]},{"cell_type":"markdown","id":"26d81dd0","metadata":{"id":"26d81dd0"},"source":["##### Custom Data Collator\n","This custom collator finds the separator between the Comment and the Code. It sets the labels for the Comment to `-100`, which tells PyTorch to ignore them during loss calculation."]},{"cell_type":"code","execution_count":9,"id":"fcd25438","metadata":{"id":"fcd25438","executionInfo":{"status":"ok","timestamp":1768904663781,"user_tz":-330,"elapsed":3,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["class CompletionCollator(DataCollatorForLanguageModeling):\n","    \"\"\"\n","    Custom collator that finds a specific separator string in the tokenized sequence\n","    and masks everything before it (the instruction), so the model only learns the code.\n","    \"\"\"\n","    def __init__(self, tokenizer, response_template=\"\\n# Solution:\\n\", *args, **kwargs):\n","        super().__init__(tokenizer=tokenizer, mlm=False, *args, **kwargs)\n","        self.response_template = response_template\n","        self.template_ids = self.tokenizer.encode(self.response_template, add_special_tokens=False)\n","\n","    def __call__(self, examples):\n","        # Tokenize the batch using parent class\n","        batch = super().__call__(examples)\n","\n","        # Set PAD labels to -100\n","        batch[\"labels\"][batch[\"labels\"] == self.tokenizer.pad_token_id] = -100\n","\n","        # Modify the labels to mask instructions\n","        for i in range(len(batch[\"labels\"])):\n","            input_ids = batch[\"input_ids\"][i].tolist()\n","            start_idx = self.find_subsequence(input_ids, self.template_ids)\n","\n","            if start_idx != -1:\n","                # The code starts after the template\n","                end_of_template = start_idx + len(self.template_ids)\n","\n","                # Mask everything before the code starts\n","                batch[\"labels\"][i, :end_of_template] = -100\n","            else:\n","                # If template not found, mask everything\n","                batch[\"labels\"][i, :] = -100\n","\n","        return batch\n","\n","    def find_subsequence(self, full_seq, pattern):\n","        \"\"\"Helper to find the start index of a sub-list (pattern) in a list\"\"\"\n","        n = len(pattern)\n","        for i in range(len(full_seq) - n + 1):\n","            if full_seq[i:i+n] == pattern:\n","                return i\n","        return -1"]},{"cell_type":"markdown","id":"82667699","metadata":{"id":"82667699"},"source":["##### Model Factory\n","We initialize the Model (with QLoRA quantization) and the Tokenizer"]},{"cell_type":"code","execution_count":10,"id":"66310d75","metadata":{"id":"66310d75","executionInfo":{"status":"ok","timestamp":1768904667309,"user_tz":-330,"elapsed":9,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["class ModelFactory:\n","    @staticmethod\n","    def create_model(config: ModelConfig):\n","        bnb_config = BitsAndBytesConfig(\n","            load_in_4bit=config.load_in_4bit,\n","            bnb_4bit_quant_type=\"nf4\",\n","            bnb_4bit_compute_dtype=config.bnb_compute_dtype,\n","            bnb_4bit_use_double_quant=True\n","        )\n","\n","        model = AutoModelForCausalLM.from_pretrained(\n","            config.model_id,\n","            quantization_config=bnb_config,\n","            device_map=\"auto\",\n","            use_cache=False,\n","            trust_remote_code=True\n","        )\n","\n","        model = prepare_model_for_kbit_training(model)\n","\n","        return model\n","\n","    @staticmethod\n","    def create_tokenizer(model_id: str):\n","        tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n","        tokenizer.pad_token = tokenizer.eos_token\n","        tokenizer.padding_side = \"right\"\n","        return tokenizer"]},{"cell_type":"markdown","id":"a67a3502","metadata":{"id":"a67a3502"},"source":["##### Custom Callbacks\n","Here we define the custom callback to fix GitHub rendering issues by providing a tabular log of training and validation loss."]},{"cell_type":"code","execution_count":11,"id":"d920e273","metadata":{"id":"d920e273","executionInfo":{"status":"ok","timestamp":1768904676975,"user_tz":-330,"elapsed":7,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["class TabularPrinterCallback(TrainerCallback):\n","    def __init__(self):\n","        self._header_printed = False\n","\n","    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, metrics=None, **kwargs):\n","        \"\"\"Called after each evaluation step\"\"\"\n","\n","        # Get train and eval loss\n","        train_loss = next((log['loss'] for log in reversed(state.log_history) if 'loss' in log), \"N/A\")\n","        eval_loss = metrics.get('eval_loss', 'N/A') if metrics else 'N/A'\n","\n","        # Get step\n","        step_str = f\"{state.global_step}/{args.max_steps}\"\n","\n","        # Print Header (only once)\n","        if not self._header_printed:\n","            print(f\"\\n{'Step':<15} | {'Train Loss':<15} | {'Eval Loss':<15}\")\n","            print(f\"{'-'*15}-+-{'-'*15}-+-{'-'*15}\")\n","            self._header_printed = True\n","\n","        # Print Row\n","        print(f\"{step_str:<15} | {train_loss:<15} | {eval_loss:<15}\")"]},{"cell_type":"markdown","id":"965b17bb","metadata":{"id":"965b17bb"},"source":["#### Main Execution\n","In this step, we -\n","\n","1. Initialize Configs\n","2. Load Data and Tokenizer\n","3. Load the Base Model\n","4. Attach LoRA Adapters (trainable layers)\n","5. Launch the SFTTrainer (Supervised Fine-Tuning) with custom logging\n","6. Save the model (adapter)"]},{"cell_type":"code","execution_count":12,"id":"b34bac63","metadata":{"id":"b34bac63","executionInfo":{"status":"ok","timestamp":1768904680251,"user_tz":-330,"elapsed":75,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["# Initialize Configs\n","model_cfg = ModelConfig()\n","lora_cfg = LoRAConfig()\n","train_cfg = TrainConfig()"]},{"cell_type":"code","execution_count":13,"id":"5c899bf6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c899bf6","executionInfo":{"status":"ok","timestamp":1768904704202,"user_tz":-330,"elapsed":23486,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}},"outputId":"d1b73609-0fd6-4b2f-dc06-220a50b4b1db"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Pipeline...\n","Loading dataset: ise-uiuc/Magicoder-Evol-Instruct-110K\n","Formatting dataset for Copilot style...\n","Train size: 44638, Validation size: 3882\n"]}],"source":["# Load Tokenizer & Data\n","print(\"Initializing Pipeline...\")\n","tokenizer = ModelFactory.create_tokenizer(model_cfg.model_id)\n","data_pipe = DataPipeline(model_cfg, tokenizer)\n","train_dataset, eval_dataset = data_pipe.load_and_prepare()"]},{"cell_type":"code","execution_count":14,"id":"6cd18e92","metadata":{"id":"6cd18e92","executionInfo":{"status":"ok","timestamp":1768904704205,"user_tz":-330,"elapsed":2,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["# Initialize Custom Collator\n","custom_collator = CompletionCollator(\n","    tokenizer=tokenizer,\n","    response_template=\"\\n# Solution:\\n\"\n",")"]},{"cell_type":"code","execution_count":15,"id":"0a6f5082","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a6f5082","executionInfo":{"status":"ok","timestamp":1768904731643,"user_tz":-330,"elapsed":24527,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}},"outputId":"5b2639c7-c5da-4777-e925-40345ca0567e"},"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 22,216,704 || all params: 1,159,424,000 || trainable%: 1.9162\n"]}],"source":["# Load Model\n","model = ModelFactory.create_model(model_cfg)\n","model.config.pad_token_id = tokenizer.eos_token_id\n","\n","# Configure LoRA\n","peft_config = LoraConfig(\n","    r=lora_cfg.r,\n","    lora_alpha=lora_cfg.alpha,\n","    lora_dropout=lora_cfg.dropout,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=lora_cfg.target_modules\n",")\n","\n","model = get_peft_model(model, peft_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":16,"id":"57195534","metadata":{"id":"57195534","executionInfo":{"status":"ok","timestamp":1768904731645,"user_tz":-330,"elapsed":1,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["# Trainer Setup\n","training_args = SFTConfig(\n","    # Precision & Hardware\n","    bf16=train_cfg.bf16,\n","    fp16=train_cfg.fp16,\n","    gradient_checkpointing=train_cfg.gradient_checkpointing,\n","\n","    # Data Processing\n","    dataset_text_field=train_cfg.dataset_text_field,\n","    max_length=train_cfg.max_length,\n","    packing=train_cfg.packing,\n","    group_by_length=train_cfg.group_by_length,\n","\n","    # Training Loop & Optimization\n","    max_steps=train_cfg.max_steps,\n","    per_device_train_batch_size=train_cfg.batch_size,\n","    gradient_accumulation_steps=train_cfg.grad_accum,\n","    optim=train_cfg.optim,\n","    lr_scheduler_type=train_cfg.lr_scheduler_type,\n","    learning_rate=train_cfg.learning_rate,\n","    warmup_steps=train_cfg.warmup_steps,\n","    weight_decay=train_cfg.weight_decay,\n","\n","    # Evaluation\n","    eval_strategy=train_cfg.eval_strategy,\n","    eval_steps=train_cfg.eval_steps,\n","    per_device_eval_batch_size=train_cfg.eval_batch_size,\n","\n","    # Logging\n","    disable_tqdm = train_cfg.disable_tqdm,\n","    logging_strategy=train_cfg.logging_strategy,\n","    logging_steps = train_cfg.logging_steps,\n","    report_to=train_cfg.report_to,\n","\n","    # Checkpoints & Saving\n","    output_dir=train_cfg.output_dir,\n","    save_strategy=train_cfg.save_strategy,\n","    save_steps=train_cfg.save_steps,\n","    save_total_limit=train_cfg.save_total_limit,\n","    load_best_model_at_end=train_cfg.load_best_model_at_end,\n","    metric_for_best_model=train_cfg.metric_for_best_model,\n","    greater_is_better=train_cfg.greater_is_better\n",")"]},{"cell_type":"code","execution_count":17,"id":"0bb57c8e","metadata":{"id":"0bb57c8e","executionInfo":{"status":"ok","timestamp":1768904795466,"user_tz":-330,"elapsed":63820,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}}},"outputs":[],"source":["trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    processing_class=tokenizer,\n","    data_collator=custom_collator,\n","    args=training_args,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=train_cfg.patience), TabularPrinterCallback()]\n",")\n","\n","# Remove Default Logger\n","trainer.remove_callback(PrinterCallback)"]},{"cell_type":"code","execution_count":18,"id":"82157feb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2449667,"status":"ok","timestamp":1768907245135,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"},"user_tz":-330},"id":"82157feb","outputId":"36080fc9-da1e-46b3-979e-73a6eb3f15d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n"]},{"output_type":"stream","name":"stdout","text":["Starting Training...\n","\n","Step            | Train Loss      | Eval Loss      \n","----------------+-----------------+----------------\n","200/4000        | 0.5665          | 0.523872971534729\n","400/4000        | 0.5362          | 0.5133563876152039\n","600/4000        | 0.5225          | 0.49929407238960266\n","800/4000        | 0.5168          | 0.4934311807155609\n","1000/4000       | 0.5165          | 0.4880228638648987\n","1200/4000       | 0.5043          | 0.4815034866333008\n","1400/4000       | 0.4951          | 0.49490422010421753\n","1600/4000       | 0.4648          | 0.48559293150901794\n","1800/4000       | 0.4576          | 0.4859406352043152\n"]}],"source":["# Start Training\n","print(\"Starting Training...\")\n","_ = trainer.train() # Suppress 'TrainOutput'"]},{"cell_type":"code","execution_count":19,"id":"ac1cdeb8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac1cdeb8","executionInfo":{"status":"ok","timestamp":1768907245985,"user_tz":-330,"elapsed":848,"user":{"displayName":"ETI-COLAB2","userId":"09720841400139439457"}},"outputId":"e4cb6f67-ef9f-4cdd-d3fb-38e4f5815d43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Saving final model...\n","Model saved successfully!\n"]}],"source":["# Save the model\n","print(\"Saving final model...\")\n","trainer.save_model(model_cfg.tuned_model_id)\n","print(\"Model saved successfully!\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":5}